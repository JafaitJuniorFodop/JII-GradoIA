{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Example 1:**\n",
        "We will use K-means to perform color segmentation on an image.\n",
        "\n",
        "<br>\n",
        "\n",
        "[Idoia Ochoa](https://portalcientifico.unav.edu/investigadores/329427/detalle) (Tecnun, University of Navarra)\n",
        "\n",
        "<br>\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/iochoa/JII-GradoIA/blob/main/notebooks/JII_1_Kmeans_ColorSegmentation_easier_2024.ipynb)\n"
      ],
      "metadata": {
        "id": "UYDJpjiMr9HA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common imports and loading image"
      ],
      "metadata": {
        "id": "UfDU24P3uhwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first import some common Python libraries"
      ],
      "metadata": {
        "id": "_Sb6jwYFSYmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For images and importing\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For arrays\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jtdLysUASc3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now read the image to which we will apply color segmentation.\n",
        "\n",
        "At the end of the notebook you have code with an example on how to load a different image from the internet, as well as loading one of your pics stored in Google Drive. Just be mindful with the size of the image..."
      ],
      "metadata": {
        "id": "l_Kw0w6cSfrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "path_img_small = 'https://raw.githubusercontent.com/iochoa/ml-datasets/main/mandrill-small.tiff'\n",
        "\n",
        "response = requests.get(path_img_small)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "DiZxEXDpsFA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check teh size of the Mandrill image"
      ],
      "metadata": {
        "id": "TV2vLrpvTzo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check its size\n",
        "rgb_pixels = np.array(img)\n",
        "rgb_pixels.shape"
      ],
      "metadata": {
        "id": "eQQwCqweuIOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the shape make sense?"
      ],
      "metadata": {
        "id": "b9rXJ3z5ZBqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image is composed of 128 x 128 pixels, with each pixel having 3 channels (R, G, B)"
      ],
      "metadata": {
        "id": "S1diXLSSjShG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = rgb_pixels.shape[0]\n",
        "height = rgb_pixels.shape[1]\n",
        "channels = rgb_pixels.shape[2]\n",
        "print('Width is: ', width)\n",
        "print('Height is: ', height)\n",
        "print('Number of channels is: ', channels)"
      ],
      "metadata": {
        "id": "6Hr3NtskaEdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now reshape the image to a 2D-tensor (matrix) of pixels, with dimension (128*128) x 3, i.e., each component of the tensor represents a pixel, composed of 3 channels (R, G, B)."
      ],
      "metadata": {
        "id": "mseGHTZ2ZaG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the reshape function\n",
        "img_vector = np.array(img)\n",
        "img_vector = img_vector.reshape((width*height, channels))\n",
        "img_vector.shape"
      ],
      "metadata": {
        "id": "39u72XMJtu7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means clustering"
      ],
      "metadata": {
        "id": "BkXTIWFFuohc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now apply K-Means to cluster the pixels by similarity, i.e., we want to group pixels that are similar to each other (based on their R, G, B values) together.\n",
        "\n",
        "For example, we would like all red(ish) pixels to form a cluster, all blue(ish) pixels to form another cluster, and so on. The clustering algorithm K-means will do this automatically."
      ],
      "metadata": {
        "id": "T7NrOvvKbKh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Kmeans with K=16 (this will generate 16 clusters/groups)\n",
        "from sklearn.cluster import KMeans\n",
        "k = 16\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "\n",
        "# Cluster assignmet for each pixel is stored in vector 'y_pred'\n",
        "y_pred = kmeans.fit_predict(img_vector)"
      ],
      "metadata": {
        "id": "8JNrT8tuu6Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred contains the cluster assignment to each pixel (it should range from 0 to 15)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "0S4SP_AJzyQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can check how many pixels are assigned to each cluster\n",
        "np.unique(y_pred, return_counts=True)"
      ],
      "metadata": {
        "id": "_ifspTPWkaCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can generate a bar plot with the number of pixels in each cluster"
      ],
      "metadata": {
        "id": "lXipokr8b73u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count the frequency of each element\n",
        "count = Counter(y_pred)\n",
        "\n",
        "# Separate the keys (the elements in the vector) and the values (their counts)\n",
        "elements = list(count.keys())\n",
        "frequencies = list(count.values())\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(elements, frequencies)\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Number of pixels assigned to each cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s9oW50Eib_I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check how the representatives (centroids) of each of these clusters look like.\n",
        "\n",
        "A cluster representative is computed as the average of all pixels assigned to that cluster, so it can be viewed as the \"average pixel\" (it should have 3 values for the R, G, B channles).\n",
        "\n",
        "Hence, we would expect one of them to be red(ish), another one blue(ish), and so on."
      ],
      "metadata": {
        "id": "aRKBnTdYede2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the centroids to understand better how the clusters look like\n",
        "tmp = kmeans.cluster_centers_.reshape(16,1,3)\n",
        "plt.imshow(np.uint8(tmp))"
      ],
      "metadata": {
        "id": "c866QXm-en9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check their R, G, B values explicitly"
      ],
      "metadata": {
        "id": "_Guz3jicet-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.cluster_centers_"
      ],
      "metadata": {
        "id": "I6mRWJ7-fIp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also plots pixels belonging to specific clusters (groups). We would expect pixels of a cluster to loook similar to the corresponding centroid (representative).\n",
        "\n",
        "In other words, if the representative of a cluster is red(ish), the pixels of that cluster should also look red."
      ],
      "metadata": {
        "id": "3a7PQvMptzOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the cluster for which you want to plot pixels assigned to it\n",
        "cluster = 4\n",
        "\n",
        "# Select the first 100 pixels\n",
        "pixels_in_cluster = img_vector[y_pred == cluster][0:100]\n",
        "\n",
        "# Reshape them to 10x10 for visualization purposes\n",
        "tmp1 = pixels_in_cluster.reshape(10, 10, 3)\n",
        "\n",
        "# Plot them\n",
        "plt.imshow(np.uint8(tmp1))"
      ],
      "metadata": {
        "id": "QYe8vfPamu4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Color segmentation (compression)"
      ],
      "metadata": {
        "id": "zeQ1TrOdvDT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will substitute all pixels belonging to a cluster, by the representative of that cluster.\n",
        "\n",
        "After this transformation, the pixels of the newly generated image can take only 16 colors, those of the centroids (see above)."
      ],
      "metadata": {
        "id": "oVl3cBOvvMOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsitute each pixel by the representative of the cluster they belong to\n",
        "new_image_vector = kmeans.cluster_centers_[y_pred]\n",
        "new_image_vector.shape"
      ],
      "metadata": {
        "id": "U-0-dZ5V2S0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a closer look at the first pixel, to make sure the new value correspond indeed to the corresponding centroid"
      ],
      "metadata": {
        "id": "ceYQid4Lvl9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the pixel value (R,G,B) of the first pixel\n",
        "print('New pixel: ', new_image_vector[0])\n",
        "\n",
        "# Cluster assignment of the first pixel\n",
        "print('Cluster assignment: ', y_pred[0])\n",
        "\n",
        "# Centroid of that cluster\n",
        "print('Centroid of cluster ', y_pred[0], ' is ', kmeans.cluster_centers_[y_pred[0]])"
      ],
      "metadata": {
        "id": "7epM0vBW34F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now plot the newly generated image that has only 16 unique pixels in it"
      ],
      "metadata": {
        "id": "N3w-OcxdwK5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape back to (128,128,3) to plot it\n",
        "new_image = new_image_vector.reshape(width,height,channels)\n",
        "\n",
        "# Plot new image\n",
        "plt.imshow(np.uint8(new_image))"
      ],
      "metadata": {
        "id": "N4fnrIQu2wLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the original image for comparison\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "odIA20o042hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the reconstruction changes for different values of K (number of clusters). Recall that K corresponds to the number of unique pixels in the reconstructed (newly generated) image."
      ],
      "metadata": {
        "id": "tdBZumBawYUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# values of K to test\n",
        "knumber = [5, 10, 16, 32, 64, 128]\n",
        "\n",
        "# Apply k-means iteratively for each k\n",
        "f, axarr = plt.subplots(2,3)\n",
        "row = 0\n",
        "col = 0\n",
        "for k in knumber:\n",
        "  kmeans = KMeans(n_clusters=k)\n",
        "  y_pred = kmeans.fit_predict(img_vector)\n",
        "  new_image_vector = kmeans.cluster_centers_[y_pred]\n",
        "  new_image = new_image_vector.reshape(128,128,3)\n",
        "  axarr[row,col].imshow(np.uint8(new_image))\n",
        "  axarr[row,col].set_title(f\"K=%d\" % k)\n",
        "  col += 1\n",
        "  if col == 3:\n",
        "    row = 1\n",
        "    col = 0"
      ],
      "metadata": {
        "id": "My4G6Lq64_LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using other images"
      ],
      "metadata": {
        "id": "AZUxvb25wv1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a different image from the internet"
      ],
      "metadata": {
        "id": "NODfYhYXwzXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just modify the path to point to the image, for example:\n",
        "path_tiger = \"https://cdn.britannica.com/22/226322-050-C17930D6/Bengal-tiger-Panthera-tigris-tigris-Maharastra-India.jpg\"\n",
        "\n",
        "response = requests.get(path_tiger)\n",
        "img_web = Image.open(BytesIO(response.content))\n",
        "plt.imshow(img_web)"
      ],
      "metadata": {
        "id": "yT9sm4LoWji_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using an image located in your Google Drive"
      ],
      "metadata": {
        "id": "SlmGCTw1w7uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive so that you can access the picture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WV4beIANWo-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path of your image\n",
        "# Note that your Google Drive path ALWAYS starts with \"/content/drive/MyDrive/\"\n",
        "path_google_drive = \"/content/drive/MyDrive/courses/JII-NuevoGrado/mandrill-small.tiff\"\n",
        "path_google_drive = \"/content/drive/MyDrive/courses/JII-NuevoGrado/picture-family-LQ.jpg\""
      ],
      "metadata": {
        "id": "IKdg_WQRWrNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the image to which we want to apply color segmentation and plot it\n",
        "import PIL\n",
        "img = PIL.Image.open(path_google_drive)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "Uy2JyWXXWtDQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
